# å­˜å‚¨æ¨¡å—ï¼šè´Ÿè´£æ–‡ä»¶ç³»ç»Ÿæ“ä½œï¼Œä¿å­˜ç« èŠ‚å†…å®¹å’Œç´¢å¼•
#ä¸»ç¨‹åºåªéœ€è¦æŠŠæ•°æ®æ‰”ç»™å®ƒï¼Œä¸éœ€è¦å…³å¿ƒæ–‡ä»¶æ€ä¹ˆå­˜ã€å­˜å“ªé‡Œã€‚
# 1. ç›®å½•ç»“æ„ï¼šdownloads/[ä½œè€…] å°è¯´å/chapters/
# 2. æ¯ç« ä¿å­˜ä¸ºå•ç‹¬çš„æ–‡æœ¬æ–‡ä»¶ï¼Œå‘½åæ ¼å¼ï¼š0001_ç« èŠ‚æ ‡é¢˜.txt
# 3. ç´¢å¼•æ–‡ä»¶ï¼šindex.jsonï¼Œè®°å½•å·²ä¸‹è½½ç« èŠ‚çš„ URL å’Œå¯¹åº”çš„æ–‡ä»¶åï¼Œæ–¹ä¾¿æ–­ç‚¹ç»­ä¼ 


import os
import json
import re
import aiofiles
import logging

logger = logging.getLogger(__name__)

class StorageHandler:
    def __init__(self, novel_name, author="Unknown"):
        self.novel_name = self._clean_str(novel_name)
        self.author = self._clean_str(author)
        
        # 1. æ„å»ºæ ‡å‡†ç›®å½•: downloads/[ä½œè€…] å°è¯´å/
        # å¦‚æœä½œè€…ååŒ…å« "ä½œ è€…ï¼š" è¿™ç§å‰ç¼€ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ¸…æ´—ï¼Œæˆ–è€…åœ¨çˆ¬è™«é‡Œæ¸…æ´—
        self.base_dir = os.path.join("downloads", f"[{self.author}] {self.novel_name}")
        self.chapter_dir = os.path.join(self.base_dir, "chapters")
        
        # 2. åˆå§‹åŒ–ç›®å½•
        os.makedirs(self.chapter_dir, exist_ok=True)
        
        # 3. åŠ è½½æˆ–åˆå§‹åŒ–ç´¢å¼• (ç”¨äºæ–­ç‚¹ç»­ä¼ )
        self.index_path = os.path.join(self.base_dir, "index.json")
        self.downloaded_chapters = self._load_index()

    def _clean_str(self, s):
        """æ¸…æ´—å­—ç¬¦ä¸²ï¼Œå»é™¤éæ³•å­—ç¬¦"""
        if not s: return "Unknown"
        # å»æ‰æ–‡ä»¶åé‡Œçš„éæ³•å­—ç¬¦
        return re.sub(r'[\\/*?:"<>|]', "", s).strip()

    def _load_index(self):
        """è¯»å–å·²ä¸‹è½½çš„ç« èŠ‚åˆ—è¡¨"""
        if os.path.exists(self.index_path):
            try:
                with open(self.index_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception:
                return {}
        return {}

    def save_meta(self, meta_info):
        """ä¿å­˜å°è¯´å…ƒæ•°æ® (meta.json)"""
        path = os.path.join(self.base_dir, "meta.json")
        try:
            with open(path, 'w', encoding='utf-8') as f:
                json.dump(meta_info, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ“š å…ƒæ•°æ®å·²ä¿å­˜: {path}")
        except Exception as e:
            logger.error(f"å…ƒæ•°æ®ä¿å­˜å¤±è´¥: {e}")

    def is_downloaded(self, chapter_url):
        """æ£€æŸ¥è¯¥ç« èŠ‚æ˜¯å¦å·²ç»ä¸‹è½½è¿‡"""
        return chapter_url in self.downloaded_chapters

    async def save_chapter(self, idx, title, content, url):
        """
        ä¿å­˜ç« èŠ‚å†…å®¹ï¼Œå¹¶æ›´æ–°ç´¢å¼•
        """
        safe_title = self._clean_str(title)
        filename = f"{idx:04d}_{safe_title}.txt"
        filepath = os.path.join(self.chapter_dir, filename)

        try:
            # 1. å†™å…¥æ–‡æœ¬æ–‡ä»¶
            async with aiofiles.open(filepath, 'w', encoding='utf-8') as f:
                await f.write(f"{title}\n\n")
                await f.write(content)
            
            # 2. æ›´æ–°å†…å­˜ä¸­çš„ç´¢å¼•
            self.downloaded_chapters[url] = {
                "idx": idx,
                "title": safe_title,
                "file": filename
            }
            
            # 3. (å¯é€‰) å®æ—¶å†™å…¥ç´¢å¼•æ–‡ä»¶ï¼Œé˜²æ­¢ç¨‹åºå´©æºƒä¸¢å¤±è¿›åº¦
            # ä¸ºäº†æ€§èƒ½ï¼Œä¹Ÿå¯ä»¥æ¯ä¸‹è½½10ç« å­˜ä¸€æ¬¡ï¼Œè¿™é‡Œä¸ºäº†å®‰å…¨æ¯æ¬¡éƒ½å­˜
            with open(self.index_path, 'w', encoding='utf-8') as f:
                json.dump(self.downloaded_chapters, f, ensure_ascii=False)
                
            logger.info(f"âœ… [{idx}] ä¿å­˜æˆåŠŸ: {title}")
            
        except Exception as e:
            logger.error(f"âŒ å†™å…¥æ–‡ä»¶å¤±è´¥: {title} - {e}")